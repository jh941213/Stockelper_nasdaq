{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 질문이 없어서 답변을 드릴 수 없습니다. 어떤 주식 관련 질문이든지 제가 알고 있는 지식과 경험을 바탕으로 정확한 답변을 드리겠습니다. 예를 들어, \"어떤 주식 종목을 추천하시나요?\" 또는 \"주식 시장 동향은 어떻게 되나요?\"와 같은 질문도 가능합니다. 언제든지 물어보세요!테스트 질문이 없어서 답변을 드릴 수 없습니다. 어떤 주식 관련 질문이든지 제가 알고 있는 지식과 경험을 바탕으로 정확한 답변을 드리겠습니다. 예를 들어, \"어떤 주식 종목을 추천하시나요?\" 또는 \"주식 시장 동향은 어떻게 되나요?\"와 같은 질문도 가능합니다. 언제든지 물어보세요!\n"
     ]
    }
   ],
   "source": [
    "from clova import HyperCLOVAChatModel\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# 벡터 저장소 초기화\n",
    "loader = TextLoader(\"/Users/kdb/Desktop/stockelper/hyperclova/context.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "# HyperCLOVA 모델 초기화\n",
    "chat_model = HyperCLOVAChatModel(\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    top_p=0.8,\n",
    "    top_k=0,\n",
    "    repeat_penalty=5.0\n",
    ")\n",
    "\n",
    "# 테스트용 질문\n",
    "query = \"여기에 테스트 질문을 입력하세요\"\n",
    "\n",
    "# 관련 문서 검색\n",
    "relevant_docs = vectorstore.similarity_search(query)\n",
    "context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "# 프롬프트 구성\n",
    "prompt = f\"\"\"다음 컨텍스트를 바탕으로 질문에 답변해주세요:\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문: {query}\n",
    "답변:\"\"\"\n",
    "\n",
    "messages = [HumanMessage(content=prompt)]\n",
    "\n",
    "# 스트리밍 응답 출력\n",
    "for chunk in chat_model.stream(messages):\n",
    "    if \"data:\" in chunk.content:\n",
    "        try:\n",
    "            data_str = chunk.content.split(\"data:\")[1].strip()\n",
    "            data = json.loads(data_str)\n",
    "            if 'message' in data and 'content' in data['message']:\n",
    "                content = data['message']['content']\n",
    "                if content:\n",
    "                    print(content, end='', flush=True)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "print()  # 줄바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kospi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
